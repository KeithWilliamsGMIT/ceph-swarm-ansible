# Ceph Swarm Ansible

This repository shows how to setup a Ceph cluster running in Docker Swarm using Ansible to automate the task. This repository is heavily based on [ceph-swarm](https://github.com/sepich/ceph-swarm) by sepich. There are other tools and methods of creating a Ceph cluster. However, this repository was created to learn new technologies and to experiment with running Ceph in Docker Swarm.

**NOTE:** The playbooks in this repository were written and tested with Ceph **Nautilus**. It may not work with newer versions of Ceph out of the box.

## Getting Started

The first step to getting started is to clone the repository:

```bash
git clone https://github.com/KeithWilliamsGMIT/ceph-swarm-ansible.git
```

We can use Vagrant to quickly spin up a small cluster of virtual machines loaclly to deploy Ceph to. The same steps should work in a cloud environment or with any computers connected by a network. Follow the steps in the [vagrant-swarm-ansible](https://github.com/KeithWilliamsGMIT/vagrant-swarm-ansible.git) repository to create the cluster of two Ubuntu 18.04 virtual machines. One will be the Swarm manager and the other will be the Swarm worker. These virtual machines will also have a virtual hard disk attached which replicate secondary storage and can be used by Ceph.

Once the Vagrant cluster is setup we can start deploying the Ceph cluster to them. First install Ansible and then we can use two existing Ansible roles to install Docker and initialise a Docker Swarm. These roles are defined in the `requirements.yml` file and will be installed to `~/.ansible/roles/` by default using the below commands:

```bash
cd playbooks/requirements
ansible-galaxy install -r requirements.yml
```

We can install [Docker](https://docs.docker.com/install/) on all the virtual machines now using the `install-docker.yml` playbook as shown below:

```bash
cd playbooks
ansible-playbook -i ~/vagrant-swarm-ansible/.vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory install-docker.yml
```

Note that we use the inventory file generated by Vagrant. Similarly, to initialise a Docker Swarm between this cluster of virtual machines we can run the `initialize-swarm.yml` playbook. Note that we set extra variables to override some defaults in the playbook. We want to skip everything except the actual initialisation of Docker Swarm. Also, note that when using this playbook with a cluster of virtual machines created with Vagrant we need to set another variable to override the default network interface and instead use the private network which is `eth1`.

```bash
ansible-playbook -i ~/vagrant-swarm-ansible/.vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory initialize-swarm.yml --extra-vars="{'skip_engine': 'True', 'skip_group': 'True', 'skip_docker_py': 'True', 'docker_swarm_interface': 'eth1'}"
```

Finally, we can deploy the stack containing all of our Ceph services, including managers, monitors, OSDs and metadata servers, to Docker Swarm using the `deploy-storage.yml` playbook. Again, similar to what we did when initialising Docker Swarm, we explicitly set the network interface as the default interface on the virtual machines don't point to the private network where they have unique IP addresses.

```bash
ansible-playbook -i ../vagrant/.vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory deploy-storage.yml --extra-vars="{'ceph_interface': 'eth1'}" --ask-vault-pass --ask-become-pass
```

The `--ask-vault-pass` flag will prompt you for the vault password to access sensitive data. A default password used in this case, for demostraion purposes, is `password`. This playbook creates a directory called `out` by default where a number of files are output to. This directory is ignored by Git.

## Does it work?

Once you followed the above steps we can check if all the services are running as expected by sshing into `node1` as thats the Docker manager by default.

```bash
ubuntu:~/vagrant-swarm-ansible/playbooks$ vagrant ssh node1
...
vagrant@node1:~$ sudo docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                           PORTS
k2h00xetv8e6        storage_mds         replicated          2/2                 ceph/daemon:latest-nautilus
b8b0ic2eq8ru        storage_mgr         replicated          1/1                 ceph/daemon:latest-nautilus
p4ao16o126w1        storage_mon         global              1/1                 ceph/daemon:latest-nautilus
wrdzdyw2u0fs        storage_osd         global              2/2                 ceph/daemon:latest-nautilus
```

We can check if the files are accessible from both nodes by sshing into `node1` and creating a file in the `/mnt/ceph` directoy. Then sshing into `node2` and checking if the changes are reflected in the same folder.

```bash
ubuntu:~/vagrant-swarm-ansible/playbooks$ vagrant ssh node1
...
vagrant@node1:~$ touch /mnt/ceph/test
vagrant@node1:~$ ls -al /mnt/ceph/
-rw-r--r-- 1 root root    0 Jun  7 19:48 test
vagrant@node1:~$ exit

...

ubuntu:~/vagrant-swarm-ansible/playbooks$ vagrant ssh node2
...
vagrant@node2:~$ ls -al /mnt/ceph/
-rw-r--r-- 1 root root    0 Jun  7 19:48 test
vagrant@node2:~$ exit
```

## Using this role

To use this role add the following to your `requirements.yml` file:

```
- src: https://github.com/KeithWilliamsGMIT/ceph-swarm-ansible.git
  version: master
  name: deploy-storage
```

## Troubleshooting

Here are a few tips you can try to troubleshoot any issues you may encounter:

+ Make sure all services in the storage stack are running as expected.
+ If a service fails to start enable verbose logging on that service, rerun the playbook and inspect the logs for more information.
+ Try adding your user to the `docker` group for each node before rerunning the playbook.
+ Ensure you are setting the correct network interface when running the playbook and that each node can be pinged successfully.

## Contributing

Any contribution to this repository is appreciated, whether it is a pull request, bug report, feature request, feedback or even starring the repository. Some potential areas that need further refinement are:

+ Updating playbooks to work with newer versions of Ceph
+ Hardening of playbooks
+ Making playbooks completely idempotent
+ Improving error handling
+ Publishing to Ansible Galaxy
+ Choosing which Ceph modules are enabled
+ Documentation
+ Upgrade to Ceph 15 (Octopus)

## Conclusion

This repository demonstates a number of different technologies and how they can be used together. Vagrant is a powerful tool to quickly and cheaply simulate cloud environments locally which is required to test this repository. Running Ceph within Docker Swarm was an interesting experiment and seems to work as expected. Finally, running all of these commands manually everytime we need to deploy Ceph would be extremely time consuming and error prone so Ansible is quite useful in this case.
